<!DOCTYPE html>
<html>
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-YCLFRZVZ1J"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-YCLFRZVZ1J');
  </script>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>FreeUV</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><span style="color: #a67a7a;">FreeUV</span>: Ground-Truth-Free Realistic Facial UV Texture Recovery via Cross-Assembly Inference Strategy</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yangxingchao.github.io/publications/" target="_blank">Xingchao Yang</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://taketomitakafumi.sakura.ne.jp/web/en/" target="_blank">Takafumi Taketomi</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.cgg.cs.tsukuba.ac.jp/~endo/index_en.html" target="_blank">Yuki Endo</a><sup>2</sup>
                    <span class="author-block">
                      <a href="http://kanamori.cs.tsukuba.ac.jp/index.html" target="_blank">Yoshihiro Kanamori</a><sup>2</sup>
                    </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup> CyberAgent, AI Lab &nbsp;<sup>2</sup> University of Tsukuba <br>CVPR 2025 </span>
                    <span class="eql-cntrb"><small><br>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2503.17197.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/EG2023_MakeupExtraction_Supplementary.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YangXingchao/FreeUV" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.17197" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.jpg" alt="Banner image" height="100%">
      <h2 class="subtitle has-text-centered">
        FreeUV generates a complete UV texture from a single face image without requiring ground-truth UV supervision during training. The method captures intricate details, such as facial hair, wrinkles, occlusions, and makeup, while demonstrating robustness across diverse scenarios, achieving high fidelity and coherent texture recovery.
        <br>
        Top to bottom: input face images, recovered UV textures, and FLAME model-based rendering.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->



<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/eg_makeup_2023.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered"><br>
        3D Avatar is widely used in movies and advertisements, with facial makeup being a crucial aspect of creating these lifelike digital characters. However, the process of editing makeup on a 3D face or using specialized equipment can be time-consuming. To obtain facial makeup for 3D characters, we propose a method to extract makeup from a single face image in a UV format that can be used for 3D face models. We unwarp the input image to UV texture so that it can be applied to a 3D face model. Then, we decompose the UV texture to bare skin, makeup, and lighting effects.
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recovering high-quality 3D facial textures from single-view 2D images is a challenging task, especially under the constraints of limited data and complex facial details such as wrinkles, makeup, and occlusions. In this paper, we introduce <span style="color: #a67a7a; font-weight: bold;">FreeUV</span>, a novel <strong>ground-truth-free</strong> UV texture recovery framework that eliminates the need for annotated or synthetic UV data. FreeUV leverages a pre-trained stable diffusion model alongside a Cross-Assembly inference strategy to fulfill this objective. In FreeUV, separate networks are trained independently to focus on realistic appearance and structural consistency, and these networks are combined during inference to generate coherent textures. Our approach accurately captures intricate facial features and demonstrates robust performance across diverse poses and occlusions. Extensive experiments validate FreeUV's effectiveness, with results surpassing state-of-the-art methods in both quantitative and qualitative metrics. Additionally, FreeUV enables new applications, including local editing, facial feature interpolation, and texture recovery from multi-view images. By reducing data requirements, FreeUV offers a scalable solution for generating high-fidelity 3D facial textures suitable for real-world scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Key Idea section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Idea</h2>
        <div class="content has-text-justified">
          <div class="has-text-centered">
            <p class="has-text-centered" style="margin-top: 10px; font-size: 0.9em;">
              <strong>Selective domain utilization in FreeUV's texture recovery.</strong> Our Cross-Assembly strategy highlights how realistic appearance from in-the-wild images and structural consistency from 3DMM are selectively combined. FreeUV targets a <strong style="color: #a67a7a;">UV-to-UV</strong> mapping with a <strong style="color: #a67a7a;">Realistic and Consistent</strong> combination for optimal texture generation.
            </p>
            <img src="static/images/domain_select.jpg" alt="Key Idea Illustration" width="80%">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Key Idea section -->

<!-- Method overview section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-nine-tenths">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-centered">
          <img src="static/images/method.jpg" alt="Method Overview" width="100%">
          <p class="has-text-justified">
            FreeUV leverages two modules, the Flaw-Tolerant Detail Extractor (left) and the UV Structure Aligner (middle), to separately capture realistic appearance and structural consistency. Combined during the Cross-Assembly inference phase (right), these modules produce high-quality UV textures from single-view images, without requiring ground-truth UV data.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End method overview section -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
      <div class="item">
        <!-- Your image here -->
        <div class="has-text-centered">
          <img src="static/images/result_recons.jpg" alt="MY ALT TEXT" style="width: 50%; margin: 0 auto;"/>
        </div>
        <h2 class="subtitle has-text-centered"><br>
          Comparison of 3D face reconstruction results. Our method achieves the closest match to the original input by rendering and overlaying the recovered UV texture. Even under challenging conditions, such as extreme lighting, facial hair, and occlusions, our approach preserves fine details and color consistency.        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <div class="has-text-centered">
          <img src="static/images/result_uv.jpg" alt="MY ALT TEXT" style="width: 50%; margin: 0 auto;"/>
        </div>
        <h2 class="subtitle has-text-centered"><br>
          Comparison of facial UV texture recovery. Our method robustly produces realistic textures despite challenging inputs. Even with significant distortions, occlusions, and missing regions in the input data, the recovered UV textures retain fine details, smooth transitions, and consistent color tones.       </h2>
     </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <div class="has-text-centered">
          <img src="static/images/suppl_result_1.jpg" alt="MY ALT TEXT" style="width: 90%; margin: 0 auto;"/>
        </div>
        <h2 class="subtitle has-text-centered"><br>
          Our method outperforms HRN, FFHQ-UV, and UV-IDM in capturing fine details, achieving realism, and maintaining robustness.
        </h2>
      </div>
      <div class="item">   
        <!-- Your image here -->
        <div class="has-text-centered">
          <img src="static/images/suppl_result_2.jpg" alt="MY ALT TEXT" style="width: 90%; margin: 0 auto;"/>
        </div>
        <h2 class="subtitle has-text-centered"><br>
          Our method outperforms HRN, FFHQ-UV, and UV-IDM in capturing fine details, achieving realism, and maintaining robustness.
        </h2>
      </div>
      <div class="item">   
        <!-- Your image here -->
        <div class="has-text-centered">
          <img src="static/images/suppl_result_3.jpg" alt="MY ALT TEXT" style="width: 90%; margin: 0 auto;"/>
        </div>
        <h2 class="subtitle has-text-centered"><br>
          Our method outperforms HRN, FFHQ-UV, and UV-IDM in capturing fine details, achieving realism, and maintaining robustness.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{yang2025_freeuv,
        title={FreeUV: Ground-Truth-Free Realistic Facial UV Texture Recovery via Cross-Assembly Inference Strategy}, 
        author={Xingchao Yang and Takafumi Taketomi and Yuki Endo and Yoshihiro Kanamori},
        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        year={2025},
  }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
